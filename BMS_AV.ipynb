{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold   #For K-fold cross validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, make_scorer\n",
    "import random\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "giventrain = pd.read_csv('train_2kmZucJ.csv')\n",
    "giventest = pd.read_csv('test_oJQbWVk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7920, 3)\n",
      "(1953, 2)\n"
     ]
    }
   ],
   "source": [
    "print(giventrain.shape) #dimensions of train\n",
    "print(giventest.shape)#dimensions of test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'label', 'tweet'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "giventrain.columns # checking column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'tweet'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "giventest.columns # checking column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Type</th>\n",
       "      <th>No of Levels</th>\n",
       "      <th>Levels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>int64</td>\n",
       "      <td>7920</td>\n",
       "      <td>[1 2 3 ... 7918 7919 7920]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>int64</td>\n",
       "      <td>2</td>\n",
       "      <td>[0 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet</th>\n",
       "      <td>object</td>\n",
       "      <td>7918</td>\n",
       "      <td>['#fingerprint #Pregnancy Test https://goo.gl/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Data Type  No of Levels  \\\n",
       "id        int64          7920   \n",
       "label     int64             2   \n",
       "tweet    object          7918   \n",
       "\n",
       "                                                  Levels  \n",
       "id                            [1 2 3 ... 7918 7919 7920]  \n",
       "label                                              [0 1]  \n",
       "tweet  ['#fingerprint #Pregnancy Test https://goo.gl/...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to inspect data\n",
    "def inspect_data(data):\n",
    "    return pd.DataFrame({\"Data Type\":data.dtypes,\"No of Levels\":data.apply(lambda x: x.unique().shape[0],axis=0), \"Levels\":data.apply(lambda x: str(x.unique()),axis=0)})\n",
    "inspect_data(giventrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5894\n",
       "1    2026\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "giventrain['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id       0\n",
       "label    0\n",
       "tweet    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "giventrain.isnull().sum(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GTrain</th>\n",
       "      <th>GTest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       GTrain  GTest\n",
       "id          0    0.0\n",
       "label       0    NaN\n",
       "tweet       0    0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"GTrain\":giventrain.isnull().sum(),\"GTest\":giventest.isnull().sum()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(train == 0).sum().sum() #sum of null values \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop columns which are not significant\n",
    "noid_train=giventrain.drop([\"id\"],axis=1,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "noid_test=giventest.drop([\"id\"],axis=1,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'tweet'], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noid_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7920, 2)\n",
      "(1953, 1)\n"
     ]
    }
   ],
   "source": [
    "print(noid_train.shape) #dimensions of train\n",
    "print(noid_test.shape)#dimensions of test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Decoupling target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train =noid_train['label']\n",
    "#X_train = noid_train.copy().drop('label', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train-Test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y =noid_train['label'].tolist()\n",
    "X = noid_train.loc[:,'tweet'].tolist()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6336, 2347)\n",
      "(1584, 2347)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = TfidfVectorizer(ngram_range = (1,3), stop_words=None,min_df=10)\n",
    "X_train_tf = tokenizer.fit_transform(X_train).toarray()\n",
    "X_val_tf = tokenizer.transform(X_val).toarray()\n",
    "\n",
    "print(X_train_tf.shape)\n",
    "print(X_val_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6336, 2347)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000007\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=2000, n_iter=10, random_state=42)\n",
    "X_train_svd = svd.fit_transform(X_train_tf)\n",
    "print(svd.explained_variance_ratio_.sum())\n",
    "X_val_svd = svd.transform(X_val_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy 0.9188762626262627\n",
      "[[4464  272]\n",
      " [ 242 1358]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.94      0.95      4736\n",
      "          1       0.83      0.85      0.84      1600\n",
      "\n",
      "avg / total       0.92      0.92      0.92      6336\n",
      "\n",
      "val Accuracy 0.8806818181818182\n",
      "[[1072   86]\n",
      " [ 103  323]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.93      0.92      1158\n",
      "          1       0.79      0.76      0.77       426\n",
      "\n",
      "avg / total       0.88      0.88      0.88      1584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "logit = LogisticRegression()\n",
    "logit.fit(X_train_tf,y_train)\n",
    "\n",
    "## Predictions\n",
    "train_logit_preds = logit.predict(X_train_tf)\n",
    "val_logit_preds = logit.predict(X_val_tf)\n",
    "\n",
    "print(\"Train Accuracy\",logit.score(X_train_tf,y_train))\n",
    "print(confusion_matrix(y_train,train_logit_preds))\n",
    "print(classification_report(y_train,train_logit_preds))\n",
    "\n",
    "print(\"val Accuracy\",logit.score(X_val_tf,y_val))\n",
    "print(confusion_matrix(y_val,val_logit_preds))\n",
    "print(classification_report(y_val,val_logit_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy 0.7918244949494949\n",
      "[[3418 1318]\n",
      " [   1 1599]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.72      0.84      4736\n",
      "          1       0.55      1.00      0.71      1600\n",
      "\n",
      "avg / total       0.89      0.79      0.81      6336\n",
      "\n",
      "val Accuracy 0.7430555555555556\n",
      "[[796 362]\n",
      " [ 45 381]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.69      0.80      1158\n",
      "          1       0.51      0.89      0.65       426\n",
      "\n",
      "avg / total       0.83      0.74      0.76      1584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "NBclassifier = GaussianNB()\n",
    "NBclassifier.fit(X_train_tf, y_train)\n",
    "\n",
    "## Predictions\n",
    "train_nb_preds = NBclassifier.predict(X_train_tf)\n",
    "val_nb_preds = NBclassifier.predict(X_val_tf)\n",
    "\n",
    "print(\"Train Accuracy\",NBclassifier.score(X_train_tf,y_train))\n",
    "print(confusion_matrix(y_train,train_nb_preds))\n",
    "print(classification_report(y_train,train_nb_preds))\n",
    "\n",
    "print(\"val Accuracy\",NBclassifier.score(X_val_tf,y_val))\n",
    "print(confusion_matrix(y_val,val_nb_preds))\n",
    "print(classification_report(y_val,val_nb_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6336, 5302)\n",
      "(1584, 5302)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer_nb = TfidfVectorizer(ngram_range = (1,3), stop_words=None,min_df=5)\n",
    "X_train_tfnb = tokenizer_nb.fit_transform(X_train).toarray()\n",
    "X_val_tfnb = tokenizer_nb.transform(X_val).toarray()\n",
    "\n",
    "print(X_train_tfnb.shape)\n",
    "print(X_val_tfnb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tfnb = tokenizer_nb.transform(noid_test).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tok=tokenizer_nb.transform(noid_test[\"tweet\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1953, 5302)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tok.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy 0.9264520202020202\n",
      "[[4502  234]\n",
      " [ 232 1368]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.95      0.95      4736\n",
      "          1       0.85      0.85      0.85      1600\n",
      "\n",
      "avg / total       0.93      0.93      0.93      6336\n",
      "\n",
      "val Accuracy 0.8869949494949495\n",
      "[[1080   78]\n",
      " [ 101  325]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.93      0.92      1158\n",
      "          1       0.81      0.76      0.78       426\n",
      "\n",
      "avg / total       0.89      0.89      0.89      1584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "logit = LogisticRegression()\n",
    "logit.fit(X_train_tfnb,y_train)\n",
    "\n",
    "## Predictions\n",
    "trainnb_logit_preds = logit.predict(X_train_tfnb)\n",
    "valnb_logit_preds = logit.predict(X_val_tfnb)\n",
    "\n",
    "print(\"Train Accuracy\",logit.score(X_train_tfnb,y_train))\n",
    "print(confusion_matrix(y_train,trainnb_logit_preds))\n",
    "print(classification_report(y_train,trainnb_logit_preds))\n",
    "\n",
    "print(\"val Accuracy\",logit.score(X_val_tfnb,y_val))\n",
    "print(confusion_matrix(y_val,valnb_logit_preds))\n",
    "print(classification_report(y_val,valnb_logit_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_nb Accuracy 0.8880997474747475\n",
      "[[4027  709]\n",
      " [   0 1600]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.85      0.92      4736\n",
      "          1       0.69      1.00      0.82      1600\n",
      "\n",
      "avg / total       0.92      0.89      0.89      6336\n",
      "\n",
      "val_nb Accuracy 0.8162878787878788\n",
      "[[942 216]\n",
      " [ 75 351]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.81      0.87      1158\n",
      "          1       0.62      0.82      0.71       426\n",
      "\n",
      "avg / total       0.84      0.82      0.82      1584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "NBclassifier = GaussianNB()\n",
    "NBclassifier.fit(X_train_tfnb, y_train)\n",
    "\n",
    "## Predictions\n",
    "trainnb_nb_preds = NBclassifier.predict(X_train_tfnb)\n",
    "valnb_nb_preds = NBclassifier.predict(X_val_tfnb)\n",
    "\n",
    "print(\"Train_nb Accuracy\",NBclassifier.score(X_train_tfnb,y_train))\n",
    "print(confusion_matrix(y_train,trainnb_nb_preds))\n",
    "print(classification_report(y_train,trainnb_nb_preds))\n",
    "\n",
    "print(\"val_nb Accuracy\",NBclassifier.score(X_val_tfnb,y_val))\n",
    "print(confusion_matrix(y_val,valnb_nb_preds))\n",
    "print(classification_report(y_val,valnb_nb_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=18, max_features='sqrt',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=5,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=75, n_jobs=-1, oob_score=True, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#score_metric = make_scorer(f1_score,'label')\n",
    "## n_jobs = -1 uses all cores of processor\n",
    "## max_features is the maximum number of attributes to select for each tree\n",
    "rfc_grid = RandomForestClassifier(n_jobs=-1, max_features='sqrt', class_weight='balanced',oob_score=True)\n",
    " \n",
    "# Use a grid over parameters of interest\n",
    "## n_estimators is the number of trees in the forest\n",
    "## max_depth is how deep each tree can be\n",
    "## min_sample_leaf is the minimum samples required in each leaf node for the root node to split\n",
    "## \"A node will only be split if in each of it's leaf nodes there should be min_sample_leaf\"\n",
    "\n",
    "param_grid = {\"n_estimators\" : [10, 25, 50, 75, 100],\n",
    "           \"max_depth\" : [10, 12, 14, 16, 18, 20],\n",
    "           \"min_samples_leaf\" : [5, 10, 15, 20]}\n",
    " \n",
    "rfc_cv_grid = RandomizedSearchCV(estimator = rfc_grid, param_distributions = param_grid, cv = 3, n_iter=20 , n_jobs=8)\n",
    "rfc_cv_grid.fit(X_train_tfnb, y_train)\n",
    "rfc_cv_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_trainnb_pred = rfc_cv_grid.best_estimator_.predict(X_train_tfnb)\n",
    "rfc_valnb_pred = rfc_cv_grid.best_estimator_.predict(X_val_tfnb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "            criterion='gini', max_depth=18, max_features='sqrt',\n",
       "            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=5,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=75, n_jobs=-1, oob_score=True, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_cv_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "0.8585858585858586\n",
      "[[3954  782]\n",
      " [ 114 1486]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.83      0.90      4736\n",
      "          1       0.66      0.93      0.77      1600\n",
      "\n",
      "avg / total       0.89      0.86      0.87      6336\n",
      "\n",
      "OOB Score 0.849905303030303\n",
      "val\n",
      "0.8472222222222222\n",
      "[[952 206]\n",
      " [ 36 390]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.82      0.89      1158\n",
      "          1       0.65      0.92      0.76       426\n",
      "\n",
      "avg / total       0.88      0.85      0.85      1584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Train\")\n",
    "print(accuracy_score(y_train,rfc_trainnb_pred))\n",
    "print(confusion_matrix(y_train,rfc_trainnb_pred))\n",
    "print(classification_report(y_train,rfc_trainnb_pred))\n",
    "\n",
    "print(\"OOB Score\", rfc_cv_grid.best_estimator_.oob_score_)\n",
    "\n",
    "print(\"val\")\n",
    "print(accuracy_score(y_val,rfc_valnb_pred))\n",
    "print(confusion_matrix(y_val,rfc_valnb_pred))\n",
    "print(classification_report(y_val,rfc_valnb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Model initilization\n",
    "rfc_50 = RandomForestClassifier(n_estimators=50, max_depth=22, oob_score=True)\n",
    "# Model training\n",
    "Xrf = X_train_tfnb\n",
    "yrf = y_train\n",
    "rfc_50.fit(Xrf ,yrf )\n",
    "# Model predictions\n",
    "rfc50_train_pred = rfc_50.predict(Xrf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "0.9455492424242424\n",
      "[[4669   67]\n",
      " [ 278 1322]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.99      0.96      4736\n",
      "          1       0.95      0.83      0.88      1600\n",
      "\n",
      "avg / total       0.95      0.95      0.94      6336\n",
      "\n",
      "OOB Score 0.860479797979798\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "print(\"Train\")\n",
    "print(accuracy_score(yrf,rfc50_train_pred))\n",
    "print(confusion_matrix(yrf,rfc50_train_pred))\n",
    "print(classification_report(yrf,rfc50_train_pred))\n",
    "\n",
    "print(\"OOB Score\", rfc_50.oob_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val\n",
      "0.8541666666666666\n",
      "[[1083   75]\n",
      " [ 156  270]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.94      0.90      1158\n",
      "          1       0.78      0.63      0.70       426\n",
      "\n",
      "avg / total       0.85      0.85      0.85      1584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc50_val_pred = rfc_50.predict(X_val_tfnb)\n",
    "print(\"val\")\n",
    "print(accuracy_score(y_val,rfc50_val_pred))\n",
    "print(confusion_matrix(y_val,rfc50_val_pred))\n",
    "print(classification_report(y_val,rfc50_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weighted f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfc_test_pred = rfc_cv_grid.best_estimator_.predict(X_test_tfnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Test\")\n",
    "#print(accuracy_score(y_test,rfc_test_pred))\n",
    "#print(confusion_matrix(y_test,rfc_test_pred))\n",
    "#print(classification_report(y_test,rfc_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# as logistic model is giving good accuracy we use it on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_new=  pd.DataFrame({'id':test_tmp['EmployeeID'],'LeadershipPotentialScore':test_predicted_rf})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "testnb_logit_pred=logit.predict(test_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame({\n",
    "#    \"ID\": giventest['id'],\n",
    "#    \"Label\": logit.predict(test_tok)\n",
    "#})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tweet_pred=pd.DataFrame({\n",
    "    \"id\": giventest['id'],\n",
    "    \"label\": testnb_logit_pred\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7921</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7922</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7923</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7924</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7925</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  label\n",
       "0  7921      1\n",
       "1  7922      0\n",
       "2  7923      1\n",
       "3  7924      1\n",
       "4  7925      1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_tweet_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1953, 2)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_tweet_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tweet_pred.to_csv(\"submission_tweet.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
